# User Flow Documentation

## Overview
This document describes the complete user journey through the Requirement Analyzer application, including all major features and workflows.

---

## 1. Authentication Flow

### 1.1 Initial Access
```
User visits application
         â†“
Is user logged in? (Check localStorage token)
         â†“
    No â†’ Show Login Page
    Yes â†’ Show Dashboard
```

### 1.2 Login Process
```
User enters email and password
         â†“
Click "Login" button
         â†“
Validate credentials with backend
         â†“
Success? 
    Yes â†’ Store token & email in localStorage â†’ Redirect to Dashboard
    No â†’ Show error message â†’ Remain on login page
```

### 1.3 Logout Process
```
User clicks "Logout" button (in sidebar)
         â†“
Clear authentication tokens from localStorage
         â†“
Reset application state
         â†“
Redirect to Login Page
```

---

## 2. Main Application Flow

### 2.1 Sidebar Navigation
```
Collapsed State (w-20):
  - Only icons visible
  - Hover shows tooltips on right side
  - All navigation items available
  
Expanded State (w-72):
  - Icons + Labels visible
  - Sidebar title and subtitle visible
  - Full user information display
  - Collapse button toggles between states
```

### 2.2 Navigation Menu
```
Dashboard
â”œâ”€â”€ Home page with overview
â””â”€â”€ Quick access to recent items

Upload
â”œâ”€â”€ Select file to upload
â”œâ”€â”€ Upload to server
â””â”€â”€ Create upload record

Agentic AI
â”œâ”€â”€ Select upload
â”œâ”€â”€ Generate Epics
â”œâ”€â”€ Generate Stories
â”œâ”€â”€ Generate QA
â””â”€â”€ Generate Test Plans

Epics
â”œâ”€â”€ View all epics for selected upload
â””â”€â”€ Display epic details

Stories
â”œâ”€â”€ View all stories for selected upload
â””â”€â”€ Display story details

QA
â”œâ”€â”€ View all QA items for selected upload
â””â”€â”€ Display QA details

Test Plans
â”œâ”€â”€ View all test plans for selected upload
â””â”€â”€ Display test plan details

Search Documents â­ (NEW)
â”œâ”€â”€ Enter search query
â”œâ”€â”€ Search across vectorstore + database
â””â”€â”€ View results with metadata

History
â””â”€â”€ View confluence export history
```

---

## 3. Upload & Generation Workflow

### 3.1 File Upload Process
```
User navigates to "/upload"
         â†“
Select file from local system
         â†“
Click "Upload" button
         â†“
File sent to backend
         â†“
Backend processes file:
  - Create Upload record in database
  - Extract text from document
  - Generate embeddings using SentenceTransformer
  - Store vectors in vectorstore JSON files
         â†“
Success response
         â†“
Upload ID returned & stored
         â†“
User can now generate Epics/Stories/QA/Test Plans from this upload
```

### 3.2 Epic Generation Workflow
```
User navigates to "/agentic-ai"
         â†“
Select upload from dropdown
         â†“
Click "Generate Epics"
         â†“
Backend Flow:
  1. Retrieve upload document from storage
  2. Call EpicAgent with document content
  3. EpicAgent:
     - Uses Gemini LLM for analysis
     - Extracts epics from requirements
     - Structures with name, description, confluence_page_id
  4. Store generated epics in Epic table
         â†“
Frontend displays generated epics in table
         â†“
User can view epic details
```

### 3.3 Story Generation Workflow
```
User selects epic from Epics page
         â†“
System retrieves epic ID
         â†“
User clicks "Generate Stories for this Epic"
         â†“
Backend Flow:
  1. Retrieve epic content from database
  2. Call StoryAgent with epic data
  3. StoryAgent:
     - Uses Gemini LLM for story generation
     - Creates user stories from epic
     - Structures with title, description, acceptance criteria
  4. Store generated stories linked to epic_id
         â†“
Frontend displays stories in table
         â†“
User can view story details
```

### 3.4 QA/Test Plan Generation Workflow
```
User selects story/epic
         â†“
Click "Generate QA" or "Generate Test Plans"
         â†“
Backend Flow:
  1. Retrieve story/epic content
  2. Call QAAgent or TestPlanAgent
  3. Agent:
     - Uses Gemini LLM for generation
     - Creates test cases or test plans
     - Structures with test cases, objectives, etc.
  4. Store in QA table (type = 'qa' or 'test_plan')
         â†“
Frontend displays results in table
         â†“
User can view details and export
```

---

## 3.5 Agent Coordinator Architecture & Usage

### Overview
The **AgentCoordinator** is a centralized orchestrator that manages all agent operations and workflows. It coordinates between multiple specialized agents (EpicAgent, StoryAgent, QAAgent, TestPlanAgent, RAGAgent) to execute comprehensive requirement analysis pipelines.

### 3.5.1 Agent Coordinator Components

```
AgentCoordinator (Central Orchestrator)
â”œâ”€â”€ Initialization
â”‚   â”œâ”€â”€ Initialize all agents on startup
â”‚   â”œâ”€â”€ Set up database connections
â”‚   â”œâ”€â”€ Configure logging
â”‚   â””â”€â”€ Setup error handling
â”‚
â”œâ”€â”€ Agent Management
â”‚   â”œâ”€â”€ EpicAgent - Generates epics from documents
â”‚   â”œâ”€â”€ StoryAgent - Generates stories from epics
â”‚   â”œâ”€â”€ QAAgent - Generates QA items from stories
â”‚   â”œâ”€â”€ TestPlanAgent - Generates test plans from stories
â”‚   â”œâ”€â”€ RAGAgent - Retrieves relevant documents via semantic search
â”‚   â””â”€â”€ BaseAgent - Provides common functionality to all agents
â”‚
â”œâ”€â”€ Workflow Execution
â”‚   â”œâ”€â”€ Single agent workflow (one agent at a time)
â”‚   â”œâ”€â”€ Sequential workflow (one after another)
â”‚   â””â”€â”€ Parallel workflow (multiple agents)
â”‚
â”œâ”€â”€ Error Handling & Logging
â”‚   â”œâ”€â”€ Execution error tracking
â”‚   â”œâ”€â”€ Retry mechanisms
â”‚   â”œâ”€â”€ Detailed logging for debugging
â”‚   â””â”€â”€ Graceful degradation on failures
â”‚
â””â”€â”€ Response Management
    â”œâ”€â”€ Structured response formatting
    â”œâ”€â”€ Result aggregation
    â”œâ”€â”€ Status tracking
    â””â”€â”€ Metadata enrichment
```

### 3.5.2 Agent Workflow Execution

#### Single Agent Execution
```
Frontend Request (e.g., Generate Epics)
         â†“
AgentCoordinator receives request
         â†“
Identify required agent (EpicAgent)
         â†“
Set up execution context:
  - Load upload document
  - Prepare input data
  - Initialize agent with context
         â†“
EpicAgent.execute()
  â”œâ”€â”€ Log execution start
  â”œâ”€â”€ Call Gemini LLM with prompt
  â”œâ”€â”€ Parse LLM response
  â”œâ”€â”€ Validate output structure
  â”œâ”€â”€ Create database records
  â””â”€â”€ Log execution end
         â†“
AgentCoordinator formats response
         â†“
Return structured result to frontend
         â†“
Frontend displays generated epics
```

#### Sequential Workflow (Optional Multi-Step)
```
User initiates workflow: Upload â†’ Epics â†’ Stories â†’ QA
         â†“
AgentCoordinator.execute_workflow(upload_id)
         â†“
Step 1: Generate Epics
  â””â”€â”€ EpicAgent generates epics from document
         â†“
Step 2: Generate Stories
  â””â”€â”€ StoryAgent generates stories for each epic
         â†“
Step 3: Generate QA
  â””â”€â”€ QAAgent generates QA items for each story
         â†“
Step 4: Generate Test Plans
  â””â”€â”€ TestPlanAgent generates test plans for each story
         â†“
Collect results from all steps
         â†“
Return aggregated results to frontend
         â†“
Frontend displays complete workflow results
```

### 3.5.3 Agent Coordinator API Methods

```
1. generate_epics(upload_id)
   â””â”€â”€ Coordinates EpicAgent to generate epics
   
2. generate_stories(epic_id, upload_id)
   â””â”€â”€ Coordinates StoryAgent to generate stories
   
3. generate_qa(epic_id, story_id, upload_id)
   â””â”€â”€ Coordinates QAAgent to generate QA items
   
4. generate_test_plans(epic_id, story_id, upload_id)
   â””â”€â”€ Coordinates TestPlanAgent to generate test plans
   
5. retrieve_documents(query, upload_id, top_k)
   â””â”€â”€ Coordinates RAGAgent for semantic search
   
6. execute_workflow(upload_id)
   â””â”€â”€ Executes complete pipeline: Epics â†’ Stories â†’ QA â†’ Test Plans
   
7. get_epics(upload_id, user_id)
   â””â”€â”€ Retrieves generated epics for an upload
   
8. get_stories(epic_id, user_id)
   â””â”€â”€ Retrieves generated stories for an epic
   
9. get_qa(upload_id, user_id)
   â””â”€â”€ Retrieves generated QA items
   
10. get_test_plans(upload_id, user_id)
    â””â”€â”€ Retrieves generated test plans
```

### 3.5.4 Agent Coordinator in Agentic AI Page

```
User opens "/agentic-ai"
         â†“
Page initializes AgentCoordinator via API
         â†“
User selects upload from dropdown
         â†“
Available actions:
  â”œâ”€â”€ Generate Epics â†’ coordinator.generate_epics(upload_id)
  â”œâ”€â”€ Generate Stories â†’ coordinator.generate_stories(epic_id, upload_id)
  â”œâ”€â”€ Generate QA â†’ coordinator.generate_qa(epic_id, story_id, upload_id)
  â”œâ”€â”€ Generate Test Plans â†’ coordinator.generate_test_plans(epic_id, story_id, upload_id)
  â””â”€â”€ Execute Full Workflow â†’ coordinator.execute_workflow(upload_id)
         â†“
User clicks action button
         â†“
Request sent to AgentCoordinator endpoint
         â†“
Coordinator orchestrates agent execution
         â†“
Backend processes with selected agent
         â†“
Results stored in database
         â†“
Response returned to frontend
         â†“
Frontend displays results
         â†“
User can now:
  â”œâ”€â”€ View generated content in respective pages
  â”œâ”€â”€ Generate next level artifacts
  â””â”€â”€ Search across generated content
```

### 3.5.5 Agent Coordinator with RAGAgent

```
User navigates to "/search-documents"
         â†“
User enters search query and clicks search
         â†“
Frontend calls ragVectorStoreSearch API
         â†“
Backend routes to AgentCoordinator.retrieve_documents()
         â†“
AgentCoordinator initializes RAGAgent
         â†“
RAGAgent.execute(query):
  â”œâ”€â”€ Encode query using SentenceTransformer
  â”œâ”€â”€ Search vectorstore JSON files:
  â”‚   â”œâ”€â”€ Load all vectorstore files
  â”‚   â”œâ”€â”€ Calculate similarity for each document
  â”‚   â””â”€â”€ Collect results
  â”œâ”€â”€ Search database:
  â”‚   â”œâ”€â”€ Query Epic table
  â”‚   â”œâ”€â”€ Query QA table (type='test_plan')
  â”‚   â”œâ”€â”€ Calculate similarity for each record
  â”‚   â””â”€â”€ Collect results
  â”œâ”€â”€ Combine all results
  â”œâ”€â”€ Filter by 30% relevance threshold
  â”œâ”€â”€ Remove acceptanceCriteria text
  â”œâ”€â”€ Sort by similarity score
  â””â”€â”€ Return top 10 results
         â†“
AgentCoordinator formats response with:
  â”œâ”€â”€ Search results array
  â”œâ”€â”€ Metadata for each result
  â”œâ”€â”€ Source attribution
  â”œâ”€â”€ Similarity scores
  â””â”€â”€ Confluence links (if available)
         â†“
Response returned to frontend
         â†“
Frontend displays results with:
  â”œâ”€â”€ Source badges (Retrieval: Vectorstore/Database)
  â”œâ”€â”€ Horizontal metadata layout
  â”œâ”€â”€ Color-coded similarity
  â””â”€â”€ Clickable Confluence links
         â†“
User can:
  â”œâ”€â”€ Modify query and search again
  â”œâ”€â”€ Click links to view source documents
  â”œâ”€â”€ Click "Clear" to reset
  â””â”€â”€ Download or export results
```

### 3.5.6 Error Handling in Agent Coordinator

```
Error occurs during agent execution:
         â†“
Agent catches exception
         â†“
Log error with context:
  â”œâ”€â”€ Agent name
  â”œâ”€â”€ Operation type
  â”œâ”€â”€ Input parameters
  â”œâ”€â”€ Error message
  â”œâ”€â”€ Stack trace
  â””â”€â”€ Timestamp
         â†“
Coordinator evaluates error type:
  â”œâ”€â”€ Retryable error â†’ Attempt retry (max 3 times)
  â”œâ”€â”€ Validation error â†’ Return user-friendly message
  â”œâ”€â”€ LLM error â†’ Try alternative prompt or fail gracefully
  â””â”€â”€ System error â†’ Log and return generic error response
         â†“
If retry exhausted or non-retryable:
  â”œâ”€â”€ Format error response
  â”œâ”€â”€ Return to frontend with error details
  â””â”€â”€ Log for debugging
         â†“
Frontend displays error message:
  â”œâ”€â”€ User-friendly message
  â”œâ”€â”€ Suggestion to retry
  â””â”€â”€ Contact support if persistent
```

### 3.5.7 Agent Coordinator State Management

```
AgentCoordinator maintains:
  â”œâ”€â”€ Execution history (for logging)
  â”œâ”€â”€ Agent instances (initialized once)
  â”œâ”€â”€ Database connections (reused)
  â”œâ”€â”€ Configuration settings
  â”œâ”€â”€ Error tracking
  â””â”€â”€ Performance metrics
         â†“
Per-request context:
  â”œâ”€â”€ Upload ID
  â”œâ”€â”€ User ID (for authorization)
  â”œâ”€â”€ Agent being executed
  â”œâ”€â”€ Start time
  â”œâ”€â”€ Status (pending/executing/completed/failed)
  â””â”€â”€ Results (once completed)
```

---

## 4. Search Documents Workflow â­ (NEW)

### 4.1 Search Initiation
```
User navigates to "/search-documents"
         â†“
Sees search card with input field
         â†“
Enters search query (e.g., "camera requirements")
         â†“
Presses Enter or clicks "Search Documents"
         â†“
Button becomes disabled with loading spinner
```

### 4.2 Dual-Source Search Execution
```
Backend receives query
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Parallel Search (Two Sources)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Vectorstore Search:                  â”‚
â”‚    - Load vectorstore*.json files       â”‚
â”‚    - Encode query with SentenceTransformer
â”‚    - Calculate cosine similarity        â”‚
â”‚    - Return top results                 â”‚
â”‚                                         â”‚
â”‚ 2. Database Search:                     â”‚
â”‚    - Query Epic table                   â”‚
â”‚    - Query QA table (type='test_plan')  â”‚
â”‚    - Encode content with embeddings     â”‚
â”‚    - Calculate cosine similarity        â”‚
â”‚    - Return top results                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
Combine results from both sources
         â†“
Filter by relevance threshold (â‰¥30%)
         â†“
Remove acceptanceCriteria text
         â†“
Filter empty results after cleaning
         â†“
Sort by similarity_percentage (descending)
         â†“
Limit to top 10 results
```

### 4.3 Results Display & Filtering
```
Results returned with:
  - Source badge:
    â€¢ "Retrieval: Vectorstore" (blue)
    â€¢ "Retrieval: Database" (purple)
  - Display name based on type
  - Similarity percentage color-coded:
    â€¢ Green (>70%) = High match
    â€¢ Yellow (50-70%) = Medium match
    â€¢ Red (<50%) = Low match
  - Preview text (first 400 chars)
  - Metadata in horizontal layout:
    â€¢ For Vectorstore: File, Upload ID, Type
    â€¢ For Epics: Epic ID, Upload ID, Confluence Link
    â€¢ For Test Plans: Test Plan ID, Epic ID, Confluence Link
         â†“
User can:
  â”œâ”€â”€ Scroll through results
  â”œâ”€â”€ Click Confluence links (if available)
  â”œâ”€â”€ Modify search query
  â””â”€â”€ Click "Clear" to reset everything
```

### 4.4 No Results Scenarios
```
Scenario 1: Irrelevant Query
  - User searches for query with <30% relevance
  - Shows: "No matching documents found. Try a different search query."
  
Scenario 2: Before Search Clicked
  - User types query but hasn't clicked search
  - Shows: Only search card, no empty state message
  
Scenario 3: After Clear Button
  - User clicks "Clear" button
  - State resets: query cleared, results removed, messages cleared
  - UI returns to initial state
```

---

## 5. Data Flow Architecture

### 5.1 Upload & Embedding Storage
```
User File
    â†“
Backend Upload Handler
    â”œâ”€â”€ Create Upload record in DB
    â”œâ”€â”€ Extract text
    â””â”€â”€ Generate embeddings (SentenceTransformer: all-MiniLM-L6-v2)
    â†“
Store embeddings in vectorstore JSON:
    storage/vectorstore_upload_{ID}.json
    {
      "doc_key": {
        "text": "...",
        "embedding": [...],
        "metadata": {...}
      }
    }
```

### 5.2 Database Schema
```
Uploads Table:
  - id (PK)
  - user_id (FK)
  - filename
  - upload_date
  - created_at

Epics Table:
  - id (PK)
  - upload_id (FK)
  - name
  - content (JSON)
  - confluence_page_id
  - created_at

QA Table:
  - id (PK)
  - epic_id (FK)
  - type (epic|story|qa|test_plan)
  - content (JSON)
  - confluence_page_id
  - created_at
```

### 5.3 Search Data Sources
```
Vectorstore JSON Files
â”œâ”€â”€ Documents uploaded by users
â”œâ”€â”€ Text + Embeddings stored
â””â”€â”€ Queried via semantic similarity

Database Records
â”œâ”€â”€ Generated Epics
â”œâ”€â”€ Generated Test Plans (QA with type='test_plan')
â””â”€â”€ Queried via semantic similarity
```

---

## 6. User Interface Sections

### 6.1 Sidebar Components
```
Header (Expanded):
  - Logo: ðŸš€ Analyzer
  - Subtitle: Requirement Analysis Tool
  - Collapse button (left arrow)

Header (Collapsed):
  - Just collapse button
  - Shows tooltip on hover

Navigation:
  - 9 menu items with icons
  - Active state: Blue gradient background
  - Tooltips on hover (collapsed mode)

User Section:
  - User profile card (expanded)
    â€¢ User circle icon
    â€¢ "Logged in as" label
    â€¢ Email address (bold white)
  - Logout button (always visible)
    â€¢ Red background, hover darker red
    â€¢ Shows tooltip when collapsed

Transitions:
  - 300ms smooth width animation
  - Opacity-based tooltip fading
  - Responsive padding adjustments
```

### 6.2 Search Documents Page
```
Header:
  - Title: ðŸ” Search Documents
  - Subtitle: Description

Messages (Conditional):
  - Error: Red background, red text, visible 4 seconds
  - Success: Green background, green text, visible 4 seconds

Search Card:
  - Input field with placeholder
  - Two buttons:
    â€¢ Search Documents (orange, flex-1)
    â€¢ Clear (gray, min-width)
  - Help text with info icon

Results Section (if found):
  - Heading: "Top {count} Search Results"
  - Result cards:
    â€¢ Result number and display name
    â€¢ Source badge (blue/purple)
    â€¢ Similarity percentage (color-coded)
    â€¢ Preview text (first 400 chars)
    â€¢ Metadata in horizontal single-row layout

Empty State (after search, no results):
  - Message: "No results found for '{query}'"
  - Encourages trying different query
```

---

## 7. Feature Highlights

### 7.1 Search Features
- âœ… Dual-source search (vectorstore + database)
- âœ… Semantic similarity using SentenceTransformer
- âœ… 30% relevance threshold filtering
- âœ… acceptanceCriteria text removal
- âœ… Horizontal metadata layout
- âœ… Confluence link integration (clickable)
- âœ… Source attribution (Retrieval: Vectorstore vs Database)
- âœ… Clear button to reset search
- âœ… Responsive design
- âœ… Dark mode support

### 7.2 Sidebar Features
- âœ… Collapse/Expand toggle
- âœ… Smooth animations
- âœ… Tooltips on all icons (collapsed mode)
- âœ… White bold user email display
- âœ… User circle icon for profile
- âœ… Clean, professional design
- âœ… Dark mode support

### 7.3 Generation Features
- âœ… AI-powered epic generation
- âœ… AI-powered story generation
- âœ… AI-powered QA generation
- âœ… AI-powered test plan generation
- âœ… Recent items tracking
- âœ… Confluence export capability

---

## 8. User Journey Examples

### Example 1: Complete Workflow
```
1. Login â†’ Dashboard
2. Upload requirements document
3. Generate Epics from upload
4. Generate Stories from epic
5. Generate Test Plans from story
6. Search for specific requirements using "Search Documents"
7. Export results to Confluence
8. Logout
```

### Example 2: Quick Search
```
1. Login â†’ Dashboard
2. Click "Search Documents" in sidebar
3. Enter search query (e.g., "API authentication")
4. View results from both vectorstore and database
5. Click on Confluence links to view original documents
6. Modify query and search again
7. Click "Clear" to start fresh
```

### Example 3: Explore Generated Content
```
1. Login â†’ Dashboard
2. Navigate to "Epics" to view all generated epics
3. Click on an epic to see details
4. Navigate to "Stories" to view stories for that epic
5. Navigate to "Test Plans" to view test plans
6. Navigate to "Search Documents" to find related content
7. Compare and correlate information across sources
```

---

## 9. Error Handling

### Frontend Error Scenarios
```
1. Network Error:
   - Show error message: "Failed to search documents. Please try again."
   - Message auto-clears after 4 seconds
   
2. Empty Search Query:
   - Show error: "Please enter a search query"
   - Search button remains disabled until text entered
   
3. No Relevant Results:
   - Show error: "No matching documents found. Try a different search query."
   - Only shown after search is performed
   
4. Authentication Expired:
   - Redirect to Login Page
   - Clear stored tokens
```

### Backend Error Handling
```
1. Upload Processing Error:
   - Log error with details
   - Show user-friendly error message
   
2. LLM Generation Error:
   - Retry with exponential backoff
   - Show error if max retries exceeded
   
3. Search Execution Error:
   - Return partial results if one source fails
   - Log errors for debugging
```

---

## 10. Performance Optimizations

### Frontend Optimizations
- âœ… Lazy loading of components
- âœ… Smooth transitions with CSS animations
- âœ… Efficient state management with React hooks
- âœ… Memoization of expensive operations
- âœ… Responsive design for all screen sizes

### Backend Optimizations
- âœ… Parallel search execution (vectorstore + database)
- âœ… Efficient embedding generation
- âœ… Indexed database queries
- âœ… Filtered results before returning
- âœ… Similarity threshold to reduce false positives

---

## 11. Accessibility Features

- âœ… Semantic HTML structure
- âœ… ARIA labels and roles
- âœ… Keyboard navigation (Enter key for search)
- âœ… Color-coded similarity indicators
- âœ… Tooltips for all icons
- âœ… Clear visual hierarchy
- âœ… Dark mode support
- âœ… Responsive design for mobile

---

## Summary

The Requirement Analyzer application provides a comprehensive workflow for:
1. **Managing Requirements** - Upload, organize, and track documents
2. **Generating Artifacts** - Use AI to create epics, stories, QA, and test plans
3. **Searching Intelligently** - Find relevant content across multiple sources using semantic similarity
4. **Exporting & Sharing** - Export to Confluence and collaborate with teams

The dual-source search capability and intuitive UI make it easy for users to discover and correlate information across their entire requirements repository.
